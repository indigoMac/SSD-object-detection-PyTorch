{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kav5L6qVuud6",
        "outputId": "901a1db7-8cdd-442b-bfe7-a8c832fd3aef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaSmLpS8uxvb",
        "outputId": "3cfc3a06-c724-4ecf-91fd-d7b63fc20725"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "from model import create_ssd_model\n",
        "import config\n",
        "from dataset import VOC_CLASSES_REVERSE\n",
        "import random"
      ],
      "metadata": {
        "id": "7hn-SRkqvN-o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a color map for each class\n",
        "COLOR_MAP = {\n",
        "    1: (0, 0, 255),     # aeroplane - red\n",
        "    2: (0, 255, 0),     # bicycle - green\n",
        "    3: (255, 0, 0),     # bird - blue\n",
        "    4: (0, 255, 255),   # boat - yellow\n",
        "    5: (255, 0, 255),   # bottle - magenta\n",
        "    6: (255, 255, 0),   # bus - cyan\n",
        "    7: (128, 0, 0),     # car - maroon\n",
        "    8: (0, 128, 0),     # cat - dark green\n",
        "    9: (0, 0, 128),     # chair - navy\n",
        "    10: (128, 128, 0),  # cow - olive\n",
        "    11: (128, 0, 128),  # diningtable - purple\n",
        "    12: (0, 128, 128),  # dog - teal\n",
        "    13: (192, 192, 192),# horse - silver\n",
        "    14: (128, 128, 128),# motorbike - gray\n",
        "    15: (255, 165, 0),  # person - orange\n",
        "    16: (0, 255, 127),  # pottedplant - spring green\n",
        "    17: (216, 191, 216),# sheep - thistle\n",
        "    18: (255, 20, 147), # sofa - deep pink\n",
        "    19: (123, 104, 238),# train - medium slate blue\n",
        "    20: (0, 191, 255)   # tvmonitor - deep sky blue\n",
        "}"
      ],
      "metadata": {
        "id": "rtZPy6dgpa5o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to load the model\n",
        "def load_model(model_path, num_classes):\n",
        "    model = create_ssd_model(num_classes)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Function to perform inference on a frame\n",
        "def run_inference(model, frame):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    image_tensor = transform(frame).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def visualize_predictions(frame, predictions):\n",
        "    boxes = predictions[0]['boxes']\n",
        "    labels = predictions[0]['labels']\n",
        "    scores = predictions[0]['scores']\n",
        "\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        if score > 0.5:  # Only visualize predictions with high confidence\n",
        "            x1, y1, x2, y2 = box.int().numpy()\n",
        "            class_name = VOC_CLASSES_REVERSE[label.item()]  # Map label to class name\n",
        "            color = COLOR_MAP[label.item()]  # Get the color for the class\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, f\"{class_name}: {score:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Main function to process a video\n",
        "def process_video(model_path, video_path, output_path):\n",
        "    # Load the model\n",
        "    model = load_model(model_path, config.num_classes)\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run inference on the frame\n",
        "        predictions = run_inference(model, frame)\n",
        "\n",
        "        # Visualize predictions\n",
        "        frame = visualize_predictions(frame, predictions)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Processed video saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "pti0A9n97W2k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = '/content/drive/My Drive/ssd_model/ssd_model_300.pth'  # Path to your saved model on Google Drive\n",
        "    video_path = 'kikko_park.mp4'  # Path to the input video on Google Drive\n",
        "    output_path = '/content/drive/My Drive/ssd_model/kikko_output.mp4'  # Path to save the output video on Google Drive\n",
        "\n",
        "    process_video(model_path, video_path, output_path)"
      ],
      "metadata": {
        "id": "FxtFGOgs7jS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a8667c-1543-476f-bafe-8146fd4da606"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
            "100%|██████████| 136M/136M [00:00<00:00, 215MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed video saved to /content/drive/My Drive/ssd_model/kikko_output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = '/content/drive/My Drive/ssd_model/ssd_model_300.pth'  # Path to your saved model on Google Drive\n",
        "    video_path = 'epic_horses.mp4'  # Path to the input video on Google Drive\n",
        "    output_path = '/content/drive/My Drive/ssd_model/horses_output.mp4'  # Path to save the output video on Google Drive\n",
        "\n",
        "    process_video(model_path, video_path, output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZfEgq8M9Tpf",
        "outputId": "d3560d75-64b3-45a5-b8a1-04499a2e4741"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed video saved to /content/drive/My Drive/ssd_model/horses_output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = '/content/drive/My Drive/ssd_model/ssd_model_300.pth'  # Path to your saved model on Google Drive\n",
        "    video_path = 'funny_dog.mp4'  # Path to the input video on Google Drive\n",
        "    output_path = '/content/drive/My Drive/ssd_model/funny_dog_output_300.mp4'  # Path to save the output video on Google Drive\n",
        "\n",
        "    process_video(model_path, video_path, output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDdiW5Rq-RKV",
        "outputId": "c82ae7cd-7768-4db1-ca63-31a7364164cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed video saved to /content/drive/My Drive/ssd_model/funny_dog_output_300.mp4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}